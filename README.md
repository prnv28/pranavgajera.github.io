# Pranav Gajera

## Work Experience
**System Engineer @ Tata Consulttancy Services (_Sep 2020 - Sep 2021_)**
- Handled Java-based backend with abstraction on Hibernate and Spring Framework. The project was for the Tamil
Nadu government and was titled Ease Of Doing Business (EODB), under which the team integrated various services
into the United portal.

## Education
- M.Tech., Computer Science | IISc, Bangalore (_June 2024_) 			        		
- B.Tech., Computer Engineering | BVM Engineering College, Gujarat (_Aug 2020_)

## Technical Skills

**Programming Languages**: Java, Python, C, C++ \
**Frameworks/Tools**: PyTorch, TensorFlow, ,Git, LLVM \
**ML/DL**:
- **ML**: PCA, Linear Regression, Logistic Regression, Support Vector Machines
- **NLP**: Word embeddings, RNN, LSTM, GRU, Transformers, BERT, GPT
- **CV**: CNN, Vision Transformers
- **Graph Neural Networks** 
  
**Miscellaneous**: Data Structures, Algorithms, Quantum Computation (Beginner)

## MTech Thesis
**Quantum Machine Learning**
- Exploring the field of quantum machine learning with goal to enhance or develop quantum algorithms for
machine learning to utilize quantum benifit for computation.

## Projects

### Neural Machine Translation using Transforme
https://arxiv.org/abs/1706.03762
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Implementation of a paper on Neural Machine Translation using Transformer units from scratch to translate English to
Hindi using IITB dataset.

### Classification with Graph Convolutional Networks
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Implemented Multi-Class classification on citation network data using Multi Layer graph convolution network and
achieved SOTA classification accuracy compared to other conventional methods.

### Comparative study of contextualized word representations
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Study done on word embeddings generated by BERT and GPT2’s intermediate layers on how well these embeddings
can perform on down stream tasks compared to static word embeddings.

### Attention based machine translation
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Used Encoder-Decoder based machine translation to translate human readable dates to machine readable dates using
self attention mechanism integrated with GRU.

### Financial Sentiment Analysis
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Implemented Sentiment classification on financial news data in multi-class sentiments using DAN (Deep Averaging
Networks) and BERT’s last layer CLS tokens on pre-trained word embeddings(GLoVe) and found using BERT’s it is
giving good result even on imbalance data sets.

### Principal Component Analysis and Multi-Class Support Vector Machines
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

Implemented PCA to reduce the dimension of data points and using the lower dimensional data points implemented
Multi-Class SVM algorithms using 1-vs-all classifiers on the MNIST data-set.

### Clustering Image pixels and represent image to k depth color image
[Paper Implementation]([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))

K-means clustering algorithm is used to cluster the pixels of the image, with a given number of clusters k= 2,5,10,20,50
to represent the image with k depth color image.
